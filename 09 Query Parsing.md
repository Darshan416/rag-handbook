# ðŸ”§ Why Query Parsing is Crucial in RAG Systems

In real-world RAG (Retrieval-Augmented Generation) systems, user prompts are often conversational and messy, making them poor candidates for direct retrieval. Query parsing helps transform these prompts into optimized search queries to improve retrieval quality.

## ðŸ§  Common Query Parsing Techniques

### * LLM-based Query Rewriting (Most Widely Used)

**Approach:** Use a prompt-engineered LLM to rewrite the user's original query.
What it does:
Clarifies ambiguous phrases.
Replaces casual language with domain-specific terms.
Adds synonyms to improve recall.
Removes irrelevant or distracting details.

**Example:**
User Prompt: "I was walking my dog and my shoulder feels numb now, what's going on?"
Rewritten: "Experienced sudden shoulder pull causing 3-day numbness and finger tingling. Possible causes such as neuropathy or nerve impingement?"
Benefits: Simple to set up, significantly boosts retrieval precision, and justifies the small cost of an LLM call.

### * Named Entity Recognition (NER)

**Approach:** Extract structured entities (e.g., people, dates, locations) from the query.
**Tool Example:** Gliner model
**Use Case:** Helps in metadata filtering or improving vector search by isolating relevant components like dates, characters, or locations.

### * HyDE (Hypothetical Document Embeddings)

**Approach:**
Instead of embedding the user query, use an LLM to generate a hypothetical answer document that reflects an ideal search result.
Then, embed that synthetic document and perform vector search.

**Why it works:**
Aligns the structure and tone of the query and corpus (i.e., you're comparing document-to-document, not prompt-to-document).
**Trade-off:** Adds latency and computational overhead, but often improves retrieval accuracy in complex domains.

### âœ… Practical Advice

**Default:** Use basic LLM-based rewriting for almost all cases.
**Advanced:** Try NER or HyDE if rewriting alone doesnâ€™t yield sufficient performance, especially for complex or structured information needs.
**Optimize by Experimentation:** The right combination depends on your domain, latency constraints, and user expectations.
